{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d30102",
   "metadata": {},
   "source": [
    "# GC10-DET Defect Classifier (TensorFlow Starter)\n",
    "This notebook demonstrates how to set up a basic CNN classifier using TensorFlow and the GC10-DET metal surface defect dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe525a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install and import dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a672f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set up directories\n",
    "# Replace with the actual path where you extract your GC10-DET dataset\n",
    "base_dir = '/path/to/gc10_dataset/'  # Replace this\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032987ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Image preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=15,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b07d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot training results\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8eacad",
   "metadata": {},
   "source": [
    "## Extended Features: Transfer Learning, Grad-CAM, and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0872edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 (Alternate): Use Transfer Learning with MobileNetV2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Grad-CAM Visualization for Model Explainability\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Example usage (after training):\n",
    "# img_path = '/path/to/sample.jpg'\n",
    "# img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "# img_array = tf.keras.preprocessing.image.img_to_array(img)[np.newaxis, ...] / 255.0\n",
    "# heatmap = make_gradcam_heatmap(img_array, model, 'Conv_1')\n",
    "# plt.matshow(heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on validation data\n",
    "val_generator.reset()\n",
    "Y_pred = model.predict(val_generator, verbose=1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "class_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
